{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic\n",
    "# make sure jupyter notebook autoreload is on\n",
    "# %load_ext autoreload\n",
    "\n",
    "import typing\n",
    "import os\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import json\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# muutils\n",
    "from zanj.zanj import ZANJ, ZANJ_GLOBAL_DEFAULTS\n",
    "\n",
    "# Our Code\n",
    "from muutils.nbutils.configure_notebook import configure_notebook\n",
    "from maze_transformer.training.config import ConfigHolder, ZanjHookedTransformer, BaseGPTConfig, TrainConfig\n",
    "from maze_dataset import MazeDataset, MazeDatasetConfig\n",
    "from maze_dataset.dataset.configs import MAZE_DATASET_CONFIGS\n",
    "from maze_dataset.generation import LatticeMazeGenerators\n",
    "from maze_transformer.training.train_model import TrainingResult, train_model\n",
    "from maze_transformer.training.wandb_logger import WandbProject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set up plots with PLOT_MODE = 'inline', FIG_OUTPUT_FMT = None, FIG_BASEPATH = None\n",
      "DEVICE = device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "# set global defaults for ZANJ\n",
    "ZANJ_GLOBAL_DEFAULTS.external_array_threshold = 1024\n",
    "ZANJ_GLOBAL_DEFAULTS.external_list_threshold = 1024\n",
    "\n",
    "# paths\n",
    "PATH_EXAMPLES: Path = Path(\"../examples/\")\n",
    "PATH_DATA: Path = Path(\"../data/\")\n",
    "\n",
    "# reproducibility and device\n",
    "DEVICE = configure_notebook(seed=42, dark_mode=True)\n",
    "print(f\"{DEVICE = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(MAZE_DATASET_CONFIGS.keys()) = ['test-g3-n5-a_dfs-h75556', 'demo_small-g3-n100-a_dfs-h88371', 'demo-g6-n10K-a_dfs-h30615']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{list(MAZE_DATASET_CONFIGS.keys()) = }\")\n",
    "\n",
    "# if you want to specify a custom config, you can do so here\n",
    "CFG_CUSTOM: ConfigHolder = ConfigHolder(\n",
    "    name = \"custom\",\n",
    "    dataset_cfg = MazeDatasetConfig(\n",
    "\t\tname=\"custom-dataset\",\n",
    "\t\tgrid_n=6,\n",
    "\t\tn_mazes=10000,\n",
    "\t\tmaze_ctor=LatticeMazeGenerators.gen_dfs,\n",
    "\t),\n",
    "    model_cfg = BaseGPTConfig(\n",
    "        name=\"custom-model\",\n",
    "        act_fn=\"gelu\",\n",
    "        d_model=8,\n",
    "        d_head=4,\n",
    "        n_layers=2,\n",
    "    ),\n",
    "    train_cfg = TrainConfig(\n",
    "        name=\"custom-train\",\n",
    "        optimizer=torch.optim.RMSprop,\n",
    "        optimizer_kwargs=dict(lr=0.0001),\n",
    "        batch_size=16,\n",
    "        dataloader_cfg=dict(\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "        ),\n",
    "        intervals_count=dict(\n",
    "            print_loss=100,\n",
    "            checkpoint=5,\n",
    "            eval_fast=10,\n",
    "            eval_slow=5,\n",
    "        ),\n",
    "        validation_dataset_cfg=100,\n",
    "\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CFG_HALLWAY: ConfigHolder = ConfigHolder(\n",
    "    name = \"hallway_v3\",\n",
    "    dataset_cfg = MazeDatasetConfig(\n",
    "\t\tname=\"hallway\",\n",
    "\t\tgrid_n=7,\n",
    "\t\tn_mazes=3_000_000,\n",
    "\t\t# n_mazes=30_000,\n",
    "\t\tmaze_ctor=LatticeMazeGenerators.gen_dfs,\n",
    "        maze_ctor_kwargs=dict(\n",
    "            do_forks=False,\n",
    "        ),\n",
    "        applied_filters=[{'name': 'collect_generation_meta', 'args': (), 'kwargs': {}}],\n",
    "        seq_len_max=256,\n",
    "\t),\n",
    "    model_cfg = BaseGPTConfig(\n",
    "        name=\"custom-model\",\n",
    "        act_fn=\"gelu\",\n",
    "        d_model=128,\n",
    "        d_head=32,\n",
    "        n_layers=6,\n",
    "    ),\n",
    "    train_cfg = TrainConfig(\n",
    "        name=\"custom-train\",\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        optimizer_kwargs=dict(lr=0.0001),\n",
    "        batch_size=32,\n",
    "        dataloader_cfg=dict(\n",
    "            shuffle=False,\n",
    "            num_workers=8,\n",
    "            drop_last=False,\n",
    "        ),\n",
    "        intervals_count=dict(\n",
    "            print_loss=100,\n",
    "            checkpoint=20,\n",
    "            eval_fast=100,\n",
    "            eval_slow=50,\n",
    "        ),\n",
    "        validation_dataset_cfg=100,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for training a \"real\" demo model\n",
    "CFG_DEMO: ConfigHolder = ConfigHolder.get_config_multisource(\n",
    "    cfg_names=(\"test-g3-n5-a_dfs-h75556\", \"tiny-v1\", \"sweep-v1\"),\n",
    ")\n",
    "\n",
    "# this is smaller, for testing\n",
    "CFG_TEST: ConfigHolder = ConfigHolder.get_config_multisource(\n",
    "    cfg_names=(\"demo_small-g3-n100-a_dfs-h88371\", \"nano-v1\", \"test-v1\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is where to specify which config to actually use\n",
    "CFG: ConfigHolder = CFG_HALLWAY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"hallway_v3\",\n",
      "  \"dataset_cfg\": {\n",
      "    \"name\": \"hallway\",\n",
      "    \"fname\": \"hallway-g7-n30K-a_dfs-h49802\",\n",
      "    \"sdc_hash\": 86367718438925181581864853467393593889412451469408090965213468443030807549802,\n",
      "    \"seed\": 42,\n",
      "    \"seq_len_min\": 1,\n",
      "    \"seq_len_max\": 256,\n",
      "    \"applied_filters\": [\n",
      "      {\n",
      "        \"name\": \"collect_generation_meta\",\n",
      "        \"args\": [],\n",
      "        \"kwargs\": {}\n",
      "      }\n",
      "    ],\n",
      "    \"grid_n\": 7,\n",
      "    \"grid_shape\": [\n",
      "      7,\n",
      "      7\n",
      "    ],\n",
      "    \"n_mazes\": 30000,\n",
      "    \"maze_ctor_name\": \"gen_dfs\",\n",
      "    \"maze_ctor_kwargs\": {\n",
      "      \"do_forks\": false\n",
      "    }\n",
      "  },\n",
      "  \"model_cfg\": {\n",
      "    \"name\": \"custom-model\",\n",
      "    \"act_fn\": \"gelu\",\n",
      "    \"d_model\": 128,\n",
      "    \"d_head\": 32,\n",
      "    \"n_layers\": 6,\n",
      "    \"weight_processing\": {\n",
      "      \"are_layernorms_folded\": false,\n",
      "      \"are_weights_processed\": false\n",
      "    },\n",
      "    \"n_heads\": 4\n",
      "  },\n",
      "  \"train_cfg\": {\n",
      "    \"name\": \"custom-train\",\n",
      "    \"optimizer\": \"AdamW\",\n",
      "    \"optimizer_kwargs\": {\n",
      "      \"lr\": 0.0001\n",
      "    },\n",
      "    \"batch_size\": 32,\n",
      "    \"dataloader_cfg\": {\n",
      "      \"shuffle\": false,\n",
      "      \"num_workers\": 8,\n",
      "      \"drop_last\": false\n",
      "    },\n",
      "    \"intervals\": null,\n",
      "    \"intervals_count\": {\n",
      "      \"print_loss\": 100,\n",
      "      \"checkpoint\": 20,\n",
      "      \"eval_fast\": 100,\n",
      "      \"eval_slow\": 50\n",
      "    },\n",
      "    \"evals_max_new_tokens\": 8,\n",
      "    \"validation_dataset_cfg\": null\n",
      "  },\n",
      "  \"pretrainedtokenizer_kwargs\": null,\n",
      "  \"maze_tokenizer\": {\n",
      "    \"tokenization_mode\": \"AOTP_UT_uniform\",\n",
      "    \"max_grid_size\": 7,\n",
      "    \"vocab_size\": 60\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(CFG.summary(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to get the dataset 'hallway-g7-n30K-a_dfs-h49802'\n",
      "loading dataset from ../data/hallway-g7-n30K-a_dfs-h49802.zanj\n",
      "Got dataset hallway with 30000 items. output.cfg.to_fname() = 'hallway-g7-n30K-a_dfs-h49802'\n"
     ]
    }
   ],
   "source": [
    "# get just the dataset, generating it if needed. \n",
    "# This step can be skipped if you set `do_generate_dataset=True` when calling `train_model`\n",
    "# or if the dataset in question already exists\n",
    "\n",
    "# load the dataset\n",
    "DATASET: MazeDataset = MazeDataset.from_config(CFG.dataset_cfg, verbose=True, local_base_path=PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:17 ERROR Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwatermelontology\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/feynman/Documents_Linux/unsearch/maze-transformer/notebooks/wandb/run-20240204_180418-haee5v99</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/watermelontology/demo-notebooks/runs/haee5v99' target=\"_blank\">mild-serenity-39</a></strong> to <a href='https://wandb.ai/watermelontology/demo-notebooks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/watermelontology/demo-notebooks' target=\"_blank\">https://wandb.ai/watermelontology/demo-notebooks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/watermelontology/demo-notebooks/runs/haee5v99' target=\"_blank\">https://wandb.ai/watermelontology/demo-notebooks/runs/haee5v99</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:19 INFO config ={'__format__': 'ConfigHolder(SerializableDataclass)', 'dataset_cfg': {'__format__': 'MazeDatasetConfig(SerializableDataclass)', 'name': 'hallway', 'seq_len_min': 1, 'seq_len_max': 256, 'seed': 42, 'applied_filters': [{'name': 'collect_generation_meta', 'args': (), 'kwargs': {}}], 'grid_n': 7, 'n_mazes': 30000, 'maze_ctor': {'__name__': 'gen_dfs', '__module__': 'maze_dataset.generation.generators', '__doc__': ['generate a lattice maze using depth first search, iterative', '', '        # Arguments', '        - `grid_shape: Coord`: the shape of the grid', '        - `lattice_dim: int`: the dimension of the lattice', '          (default: `2`)', '        - `accessible_cells: int | float |None`: the number of accessible cells in the maze. If `None`, defaults to the total number of cells in the grid. if a float, asserts it is <= 1 and treats it as a proportion of **total cells**', '            (default: `None`)', '        - `max_tree_depth: int | float | None`: the maximum depth of the tree. If `None`, defaults to `2 * accessible_cells`. if a float, asserts it is <= 1 and treats it as a proportion of the **sum of the grid shape**', '            (default: `None`)', '        - `do_forks: bool`: whether to allow forks in the maze. If `False`, the maze will be have no forks and will be a simple hallway.', '        - `start_coord: Coord | None`: the starting coordinate of the generation algorithm. If `None`, defaults to a random coordinate.', '', '        # algorithm', '        1. Choose the initial cell, mark it as visited and push it to the stack', '        2. While the stack is not empty', '                1. Pop a cell from the stack and make it a current cell', '                2. If the current cell has any neighbours which have not been visited', '                        1. Push the current cell to the stack', '                        2. Choose one of the unvisited neighbours', '                        3. Remove the wall between the current cell and the chosen cell', '                        4. Mark the chosen cell as visited and push it to the stack', '        '], 'source_code': ['    @staticmethod', '    def gen_dfs(', '        grid_shape: Coord,', '        lattice_dim: int = 2,', '        accessible_cells: int | float | None = None,', '        max_tree_depth: int | float | None = None,', '        do_forks: bool = True,', '        randomized_stack: bool = False,', '        start_coord: Coord | None = None,', '    ) -> LatticeMaze:', '        \"\"\"generate a lattice maze using depth first search, iterative', '', '        # Arguments', '        - `grid_shape: Coord`: the shape of the grid', '        - `lattice_dim: int`: the dimension of the lattice', '          (default: `2`)', '        - `accessible_cells: int | float |None`: the number of accessible cells in the maze. If `None`, defaults to the total number of cells in the grid. if a float, asserts it is <= 1 and treats it as a proportion of **total cells**', '            (default: `None`)', '        - `max_tree_depth: int | float | None`: the maximum depth of the tree. If `None`, defaults to `2 * accessible_cells`. if a float, asserts it is <= 1 and treats it as a proportion of the **sum of the grid shape**', '            (default: `None`)', '        - `do_forks: bool`: whether to allow forks in the maze. If `False`, the maze will be have no forks and will be a simple hallway.', '        - `start_coord: Coord | None`: the starting coordinate of the generation algorithm. If `None`, defaults to a random coordinate.', '', '        # algorithm', '        1. Choose the initial cell, mark it as visited and push it to the stack', '        2. While the stack is not empty', '                1. Pop a cell from the stack and make it a current cell', '                2. If the current cell has any neighbours which have not been visited', '                        1. Push the current cell to the stack', '                        2. Choose one of the unvisited neighbours', '                        3. Remove the wall between the current cell and the chosen cell', '                        4. Mark the chosen cell as visited and push it to the stack', '        \"\"\"', '', '        # Default values if no constraints have been passed', '        grid_shape: Coord = np.array(grid_shape)', '        n_total_cells: int = int(np.prod(grid_shape))', '', '        n_accessible_cells: int', '        if accessible_cells is None:', '            n_accessible_cells = n_total_cells', '        elif isinstance(accessible_cells, float):', '            assert (', '                accessible_cells <= 1', '            ), f\"accessible_cells must be an int (count) or a float in the range [0, 1] (proportion), got {accessible_cells}\"', '', '            n_accessible_cells = int(accessible_cells * n_total_cells)', '        else:', '            assert isinstance(accessible_cells, int)', '            n_accessible_cells = accessible_cells', '', '        if max_tree_depth is None:', '            max_tree_depth = (', '                2 * n_total_cells', '            )  # We define max tree depth counting from the start coord in two directions. Therefore we divide by two in the if clause for neighboring sites later and multiply by two here.', '        elif isinstance(max_tree_depth, float):', '            assert (', '                max_tree_depth <= 1', '            ), f\"max_tree_depth must be an int (count) or a float in the range [0, 1] (proportion), got {max_tree_depth}\"', '', '            max_tree_depth = int(max_tree_depth * np.sum(grid_shape))', '', '        # choose a random start coord', '        start_coord = _random_start_coord(grid_shape, start_coord)', '', '        # initialize the maze with no connections', '        connection_list: ConnectionList = np.zeros(', '            (lattice_dim, grid_shape[0], grid_shape[1]), dtype=np.bool_', '        )', '', '        # initialize the stack with the target coord', '        visited_cells: set[tuple[int, int]] = set()', '        visited_cells.add(tuple(start_coord))  # this wasnt a bug after all lol', '        stack: list[Coord] = [start_coord]', '', '        # initialize tree_depth_counter', '        current_tree_depth: int = 1', '', '        # loop until the stack is empty or n_connected_cells is reached', '        while stack and (len(visited_cells) < n_accessible_cells):', '            # get the current coord from the stack', '            current_coord: Coord', '            if randomized_stack:', '                current_coord = stack.pop(random.randint(0, len(stack) - 1))', '            else:', '                current_coord = stack.pop()', '', '            # filter neighbors by being within grid bounds and being unvisited', '            unvisited_neighbors_deltas: list[tuple[Coord, Coord]] = [', '                (neighbor, delta)', '                for neighbor, delta in zip(', '                    current_coord + NEIGHBORS_MASK, NEIGHBORS_MASK', '                )', '                if (', '                    (tuple(neighbor) not in visited_cells)', '                    and (0 <= neighbor[0] < grid_shape[0])', '                    and (0 <= neighbor[1] < grid_shape[1])', '                )', '            ]', '', \"            # don't continue if max_tree_depth/2 is already reached (divide by 2 because we can branch to multiple directions)\", '            if unvisited_neighbors_deltas and (', '                current_tree_depth <= max_tree_depth / 2', '            ):', \"                # if we want a maze without forks, simply don't add the current coord back to the stack\", '                if do_forks and (len(unvisited_neighbors_deltas) > 1):', '                    stack.append(current_coord)', '', '                # choose one of the unvisited neighbors', '                chosen_neighbor, delta = random.choice(unvisited_neighbors_deltas)', '', '                # add connection', '                dim: int = np.argmax(np.abs(delta))', '                # if positive, down/right from current coord', '                # if negative, up/left from current coord (down/right from neighbor)', '                clist_node: Coord = (', '                    current_coord if (delta.sum() > 0) else chosen_neighbor', '                )', '                connection_list[dim, clist_node[0], clist_node[1]] = True', '', '                # add to visited cells and stack', '                visited_cells.add(tuple(chosen_neighbor))', '                stack.append(chosen_neighbor)', '', '                # Update current tree depth', '                current_tree_depth += 1', '            else:', '                current_tree_depth -= 1', '', '        output = LatticeMaze(', '            connection_list=connection_list,', '            generation_meta=dict(', '                func_name=\"gen_dfs\",', '                grid_shape=grid_shape,', '                start_coord=start_coord,', '                n_accessible_cells=int(n_accessible_cells),', '                max_tree_depth=int(max_tree_depth),', \"                # oh my god this took so long to track down. its almost 5am and I've spent like 2 hours on this bug\", '                # it was checking that len(visited_cells) == n_accessible_cells, but this means that the maze is', '                # treated as fully connected even when it is most certainly not, causing solving the maze to break', '                fully_connected=bool(len(visited_cells) == n_total_cells),', '                visited_cells={tuple(int(x) for x in coord) for coord in visited_cells},', '            ),', '        )', '', '        return output']}, 'maze_ctor_kwargs': {'do_forks': False}, 'grid_shape': (7, 7)}, 'model_cfg': {'__format__': 'BaseGPTConfig(SerializableDataclass)', 'name': 'custom-model', 'act_fn': 'gelu', 'd_model': 128, 'd_head': 32, 'n_layers': 6, 'weight_processing': {'are_layernorms_folded': False, 'are_weights_processed': False}, 'n_heads': 4}, 'train_cfg': {'__format__': 'TrainConfig(SerializableDataclass)', 'name': 'custom-train', 'evals_max_new_tokens': 8, 'validation_dataset_cfg': None, 'optimizer': 'AdamW', 'optimizer_kwargs': {'lr': 0.0001}, 'batch_size': 32, 'num_epochs': 1, 'dataloader_cfg': {'shuffle': False, 'num_workers': 8, 'drop_last': False}, 'intervals': None, 'intervals_count': {'print_loss': 100, 'checkpoint': 20, 'eval_fast': 100, 'eval_slow': 50}}, 'name': 'hallway_v3', 'pretrainedtokenizer_kwargs': None, 'maze_tokenizer': {'__format__': 'MazeTokenizer(SerializableDataclass)', 'tokenization_mode': 'AOTP_UT_uniform', 'max_grid_size': 7, 'name': 'maze_tokenizer-AOTP_UT_uniform-g7', 'token_arr': ['<ADJLIST_START>', '<ADJLIST_END>', '<TARGET_START>', '<TARGET_END>', '<ORIGIN_START>', '<ORIGIN_END>', '<PATH_START>', '<PATH_END>', '<-->', ';', '<PADDING>', '(0,0)', '(0,1)', '(1,0)', '(1,1)', '(0,2)', '(2,0)', '(1,2)', '(2,1)', '(2,2)', '(0,3)', '(3,0)', '(3,1)', '(2,3)', '(3,2)', '(1,3)', '(3,3)', '(0,4)', '(2,4)', '(4,0)', '(1,4)', '(4,1)', '(4,2)', '(3,4)', '(4,3)', '(4,4)', '(0,5)', '(5,0)', '(5,1)', '(2,5)', '(5,2)', '(5,3)', '(4,5)', '(5,4)', '(1,5)', '(3,5)', '(5,5)', '(0,6)', '(2,6)', '(4,6)', '(6,0)', '(1,6)', '(6,1)', '(6,2)', '(3,6)', '(6,3)', '(6,4)', '(5,6)', '(6,5)', '(6,6)'], 'tokenizer_map': {'<ADJLIST_START>': 0, '<ADJLIST_END>': 1, '<TARGET_START>': 2, '<TARGET_END>': 3, '<ORIGIN_START>': 4, '<ORIGIN_END>': 5, '<PATH_START>': 6, '<PATH_END>': 7, '<-->': 8, ';': 9, '<PADDING>': 10, '(0,0)': 11, '(0,1)': 12, '(1,0)': 13, '(1,1)': 14, '(0,2)': 15, '(2,0)': 16, '(1,2)': 17, '(2,1)': 18, '(2,2)': 19, '(0,3)': 20, '(3,0)': 21, '(3,1)': 22, '(2,3)': 23, '(3,2)': 24, '(1,3)': 25, '(3,3)': 26, '(0,4)': 27, '(2,4)': 28, '(4,0)': 29, '(1,4)': 30, '(4,1)': 31, '(4,2)': 32, '(3,4)': 33, '(4,3)': 34, '(4,4)': 35, '(0,5)': 36, '(5,0)': 37, '(5,1)': 38, '(2,5)': 39, '(5,2)': 40, '(5,3)': 41, '(4,5)': 42, '(5,4)': 43, '(1,5)': 44, '(3,5)': 45, '(5,5)': 46, '(0,6)': 47, '(2,6)': 48, '(4,6)': 49, '(6,0)': 50, '(1,6)': 51, '(6,1)': 52, '(6,2)': 53, '(3,6)': 54, '(6,3)': 55, '(6,4)': 56, '(5,6)': 57, '(6,5)': 58, '(6,6)': 59}, 'vocab_size': 60, 'padding_token_index': 10}, '_tokenizer': 'None'}\n",
      "2024-02-04 18:04:19 INFO Initialized logger\n",
      "2024-02-04 18:04:19 INFO Summary logged, getting dataset\n",
      "2024-02-04 18:04:19 INFO passed dataset has matching config, using that\n",
      "2024-02-04 18:04:19 INFO finished getting training dataset with 30000 samples\n",
      "2024-02-04 18:04:19 INFO Loaded 30000 sequences\n",
      "2024-02-04 18:04:19 INFO Creating dataloader\n",
      "2024-02-04 18:04:19 INFO finished dataloader, passing to train()\n",
      "2024-02-04 18:04:19 INFO Initializing model\n",
      "Moving model to device:  cuda\n",
      "2024-02-04 18:04:19 INFO Initializing optimizer\n",
      "2024-02-04 18:04:19 INFO will train for 938 batches, evals_enabled=False, with intervals: {'print_loss': 9, 'checkpoint': 46, 'eval_fast': inf, 'eval_slow': inf}\n",
      "2024-02-04 18:04:19 INFO Starting training\n",
      "num_epochs = 1\n",
      "epoch = 0, num_epochs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:20 INFO iteration 0/938: loss=5.053\n",
      "2024-02-04 18:04:20 INFO Saving model checkpoint to ../data/hallway_v3_2024-02-04-18-04-17/checkpoints/model.iter_0.zanj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/938 [00:03<02:57,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:22 INFO iteration 9/938: loss=2.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18/938 [00:04<02:17,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:23 INFO iteration 18/938: loss=1.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 27/938 [00:05<02:23,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:25 INFO iteration 27/938: loss=1.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 36/938 [00:06<02:06,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:26 INFO iteration 36/938: loss=1.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 45/938 [00:07<01:35,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:27 INFO iteration 45/938: loss=2.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 46/938 [00:07<01:33,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:27 INFO Saving model checkpoint to ../data/hallway_v3_2024-02-04-18-04-17/checkpoints/model.iter_46.zanj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 54/938 [00:09<01:50,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:28 INFO iteration 54/938: loss=1.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 63/938 [00:10<01:58,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:30 INFO iteration 63/938: loss=1.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 72/938 [00:11<01:45,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:31 INFO iteration 72/938: loss=1.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 81/938 [00:12<01:39,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:32 INFO iteration 81/938: loss=1.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 90/938 [00:13<01:57,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:33 INFO iteration 90/938: loss=1.339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 92/938 [00:14<02:04,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:33 INFO Saving model checkpoint to ../data/hallway_v3_2024-02-04-18-04-17/checkpoints/model.iter_92.zanj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 99/938 [00:15<02:43,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:35 INFO iteration 99/938: loss=1.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 107/938 [00:17<02:07,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:36 INFO iteration 108/938: loss=1.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 117/938 [00:18<01:35,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:37 INFO iteration 117/938: loss=1.397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 125/938 [00:19<01:43,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:38 INFO iteration 126/938: loss=1.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 135/938 [00:20<01:29,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:39 INFO iteration 135/938: loss=1.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 137/938 [00:20<01:41,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:40 INFO Saving model checkpoint to ../data/hallway_v3_2024-02-04-18-04-17/checkpoints/model.iter_138.zanj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 144/938 [00:21<02:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:41 INFO iteration 144/938: loss=1.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 153/938 [00:23<01:39,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:42 INFO iteration 153/938: loss=1.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 162/938 [00:24<01:44,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:43 INFO iteration 162/938: loss=1.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 171/938 [00:25<01:30,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:44 INFO iteration 171/938: loss=1.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 180/938 [00:26<01:35,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:45 INFO iteration 180/938: loss=1.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 184/938 [00:26<01:47,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:46 INFO Saving model checkpoint to ../data/hallway_v3_2024-02-04-18-04-17/checkpoints/model.iter_184.zanj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 189/938 [00:28<02:10,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:47 INFO iteration 189/938: loss=1.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 198/938 [00:29<01:41,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:48 INFO iteration 198/938: loss=1.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 207/938 [00:30<01:19,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:49 INFO iteration 207/938: loss=1.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 216/938 [00:31<01:35,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:50 INFO iteration 216/938: loss=1.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 224/938 [00:32<01:34,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:52 INFO iteration 225/938: loss=1.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 230/938 [00:33<01:44,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:52 INFO Saving model checkpoint to ../data/hallway_v3_2024-02-04-18-04-17/checkpoints/model.iter_230.zanj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 234/938 [00:34<02:31,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:54 INFO iteration 234/938: loss=1.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 243/938 [00:35<01:42,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:55 INFO iteration 243/938: loss=1.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 252/938 [00:37<01:34,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:56 INFO iteration 252/938: loss=1.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 261/938 [00:38<01:40,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:57 INFO iteration 261/938: loss=1.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 269/938 [00:39<01:29,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:59 INFO iteration 270/938: loss=1.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 276/938 [00:40<01:25,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:04:59 INFO Saving model checkpoint to ../data/hallway_v3_2024-02-04-18-04-17/checkpoints/model.iter_276.zanj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 279/938 [00:41<02:06,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:00 INFO iteration 279/938: loss=1.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 288/938 [00:42<01:23,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:01 INFO iteration 288/938: loss=1.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 297/938 [00:43<01:18,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:02 INFO iteration 297/938: loss=1.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 305/938 [00:44<01:25,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:04 INFO iteration 306/938: loss=1.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 315/938 [00:45<01:09,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:05 INFO iteration 315/938: loss=1.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 321/938 [00:46<01:24,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:05 INFO Saving model checkpoint to ../data/hallway_v3_2024-02-04-18-04-17/checkpoints/model.iter_322.zanj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 324/938 [00:47<02:10,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:06 INFO iteration 324/938: loss=1.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 333/938 [00:48<01:13,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:07 INFO iteration 333/938: loss=1.141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 341/938 [00:49<01:12,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:08 INFO iteration 342/938: loss=1.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 350/938 [00:50<01:12,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:09 INFO iteration 351/938: loss=1.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 360/938 [00:51<01:13,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:10 INFO iteration 360/938: loss=1.079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 368/938 [00:52<01:12,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:11 INFO Saving model checkpoint to ../data/hallway_v3_2024-02-04-18-04-17/checkpoints/model.iter_368.zanj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 369/938 [00:53<02:20,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:12 INFO iteration 369/938: loss=1.097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 378/938 [00:54<01:20,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:13 INFO iteration 378/938: loss=1.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 387/938 [00:55<01:18,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:14 INFO iteration 387/938: loss=1.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 396/938 [00:56<01:08,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:16 INFO iteration 396/938: loss=1.095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 405/938 [00:57<01:05,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:17 INFO iteration 405/938: loss=1.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 414/938 [00:58<00:58,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:18 INFO iteration 414/938: loss=1.067\n",
      "2024-02-04 18:05:18 INFO Saving model checkpoint to ../data/hallway_v3_2024-02-04-18-04-17/checkpoints/model.iter_414.zanj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 423/938 [01:00<01:11,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:19 INFO iteration 423/938: loss=1.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 432/938 [01:01<01:01,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-04 18:05:21 INFO iteration 432/938: loss=1.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 435/938 [01:01<01:11,  7.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result: TrainingResult \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPATH_DATA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mwandb_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWandbProject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEMO_NOTEBOOKS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# change this to WandbProject.DEMO_NOTEBOOKS!\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mdo_generate_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mdataset_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATASET\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents_Linux/unsearch/maze-transformer/maze_transformer/training/train_model.py:169\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(base_path, wandb_project, cfg, cfg_file, cfg_names, do_generate_dataset, dataset_verbose, dataset, allow_dataset_override, device, help, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m dataloader: DataLoader \u001b[38;5;241m=\u001b[39m get_dataloader(dataset, cfg, logger)\n\u001b[1;32m    168\u001b[0m logger\u001b[38;5;241m.\u001b[39mprogress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinished dataloader, passing to train()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 169\u001b[0m trained_model: ZanjHookedTransformer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TrainingResult(\n\u001b[1;32m    179\u001b[0m     output_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[1;32m    180\u001b[0m     model\u001b[38;5;241m=\u001b[39mtrained_model,\n\u001b[1;32m    181\u001b[0m )\n",
      "File \u001b[0;32m~/Documents_Linux/unsearch/maze-transformer/maze_transformer/training/training.py:146\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(cfg, dataloader, logger, output_dir, device, val_dataset, zanj, model)\u001b[0m\n\u001b[1;32m    144\u001b[0m loss: SingleLoss\n\u001b[1;32m    145\u001b[0m logits: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos d_vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 146\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# backward pass\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Remove the last logit because it's the prediction for what comes after PATH_END (and so is meaningless)\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Do this after computing loss because the loss_fn already ignores the last logit\u001b[39;00m\n\u001b[1;32m    152\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/Documents_Linux/unsearch/maze-transformer/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents_Linux/unsearch/maze-transformer/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents_Linux/unsearch/maze-transformer/.venv/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:405\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, stop_at_layer, past_kv_cache, past_left_attention_mask)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    402\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    403\u001b[0m         )\n\u001b[0;32m--> 405\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each block\u001b[39;49;00m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents_Linux/unsearch/maze-transformer/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents_Linux/unsearch/maze-transformer/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents_Linux/unsearch/maze-transformer/.venv/lib/python3.10/site-packages/transformer_lens/components.py:1043\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, left_attention_mask)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1037\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m add_head_dimension(shortformer_pos_embed)\n\u001b[1;32m   1039\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_attn_out(\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mattn_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m   1054\u001b[0m     resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_mid(\n\u001b[1;32m   1055\u001b[0m         resid_pre \u001b[38;5;241m+\u001b[39m attn_out\n\u001b[1;32m   1056\u001b[0m     )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents_Linux/unsearch/maze-transformer/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents_Linux/unsearch/maze-transformer/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result: TrainingResult = train_model(\n",
    "\tbase_path=PATH_DATA,\n",
    "    cfg=CFG,\n",
    "\twandb_project=WandbProject.DEMO_NOTEBOOKS, # change this to WandbProject.DEMO_NOTEBOOKS!\n",
    "\tdo_generate_dataset=False,\n",
    "\tdataset_verbose=True,\n",
    "    dataset=DATASET,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsearch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
